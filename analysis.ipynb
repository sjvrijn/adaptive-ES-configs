{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive CMA-ES configurations - Analysis\n",
    "\n",
    "This Python Notebook covers the analysis of pre-processed data for the adaptive CMA-ES research.\n",
    "\n",
    "The input data consists of CSVs with the required runtimes for each pre-specified target for all runs, separated into files for each function/dimensionality pair. For details on the pre-processing that went into creating this data, please refer to the `pre-processing.ipynb/html` notebook.\n",
    "\n",
    "An example with target values 100, 1 and 0.01:\n",
    "\n",
    "`idx |   1   2   3 ...   56   57   58   59 ...    164    165    166    167`<br>\n",
    "`val | 124 102  94 ... 1.13 1.06 0.98 0.96 ... 0.0123 0.0109 0.0098 0.0097`\n",
    "\n",
    "For section `$\\inf$-100`, the first index where the value is _below_ 100 is 3. For the next target the index is 58, and for the final target the first index is 166.\n",
    "\n",
    "\n",
    "> Sander van Rijn<br>\n",
    "> s.j.van.rijn@liacs.leidenuniv.nl<br>\n",
    "> LIACS<br>\n",
    "> 2018-03-29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.151288Z",
     "start_time": "2018-05-30T11:41:12.864043Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from collections import Counter, defaultdict\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.160327Z",
     "start_time": "2018-05-30T11:41:13.152377Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Some utility functions for dealing with the representations\n",
    "\n",
    "# First, some hardcoded variables\n",
    "num_options_per_module = [2]*9        # Binary part\n",
    "num_options_per_module.extend([3]*2)  # Ternary part\n",
    "max_length = 11\n",
    "factors = [2304, 1152, 576, 288, 144, 72, 36, 18, 9, 3, 1]\n",
    "\n",
    "def list_all_representations():\n",
    "    \"\"\" Create a list of all possible representations for the modular CMA-ES.\n",
    "        Each representation is itself a list with <max_length> integer entries {0, 1, ..., n},\n",
    "        where 'n' is the number of options for the module in that position.\n",
    "    \"\"\"\n",
    "    products = []\n",
    "    # count how often there is a choice of x options\n",
    "    counts = Counter(num_options_per_module)\n",
    "    for num, count in sorted(counts.items(), key=lambda x: x[0]):\n",
    "        products.append(product(range(num), repeat=count))\n",
    "    all_representations = []\n",
    "    for representation in list(product(*products)):\n",
    "        all_representations.append(list(sum(representation, ())))\n",
    "    return all_representations\n",
    "\n",
    "\n",
    "def reprToString(representation):\n",
    "    \"\"\" Function that converts the structure parameters of a given ES-structure representation to a string\n",
    "\n",
    "        >>> reprToInt([0,0,0,0,0,1,0,1,0,1,0])\n",
    "        >>> '00000101010'\n",
    "    \"\"\"\n",
    "    return ''.join([str(i) for i in representation[:max_length]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.182952Z",
     "start_time": "2018-05-30T11:41:13.161353Z"
    }
   },
   "outputs": [],
   "source": [
    "data_location = '/media/rijnsjvan/Data/SurfDrive/Research Data/Adaptive ES/anytime_convergence/data/'\n",
    "# file_name = 'steepness_data_{ndim}D-f{fid}.csv'\n",
    "# file_name = 'interpolated_ART_data_{ndim}D-f{fid}.csv'\n",
    "# file_name = 'stepwise_ERT_data_{ndim}D-f{fid}.csv'\n",
    "file_name = 'ERT_data_{ndim}D-f{fid}.csv'\n",
    "\n",
    "\n",
    "#TODO: Retrieve this information from the files instead?\n",
    "ndims = [5, 20]\n",
    "fids = [1, 10, 15, 20]\n",
    "\n",
    "num_steps = 51\n",
    "powers = np.round(np.linspace(2, -8, num_steps), decimals=1)\n",
    "target_values = np.power([10]*num_steps, powers)\n",
    "\n",
    "columns = ['10e{}'.format(power) for power in powers]\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=1000, edgeitems=30)\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "Using the data in (one of) the CSV files, we'll start with some exploratory analysis.\n",
    "Any useful procedures will be coded as functions, making them easy to re-use for a final full analysis later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.345845Z",
     "start_time": "2018-05-30T11:41:13.184198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(ndim, fid):\n",
    "    return pd.read_csv(data_location + file_name.format(ndim=ndim, fid=fid), index_col=0)\n",
    "\n",
    "# Starting with 5D F1 as an example\n",
    "df = get_data(ndim=5, fid=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.394358Z",
     "start_time": "2018-05-30T11:41:13.347293Z"
    }
   },
   "outputs": [],
   "source": [
    "def absolutetodifferences(df):\n",
    "    return_df = df.copy()\n",
    "    df_columns = list(reversed(columns))\n",
    "    for column_a, column_b in zip(columns, columns[1:]):\n",
    "        return_df[column_b] = df[column_b] - df[column_a]\n",
    "    return return_df\n",
    "\n",
    "# Next, we get the differences between the running times for each of the targets\n",
    "df_diff = absolutetodifferences(df)\n",
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see a problem here: Some of the smallest values are zeroes.\n",
    "This means that the actual improvement step made by the algorithm went across the specified targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.403119Z",
     "start_time": "2018-05-30T11:41:13.395664Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_diff[columns].min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.428551Z",
     "start_time": "2018-05-30T11:41:13.404158Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregateByMean(df):\n",
    "    df_means = df.groupby(by=['Representation', 'ndim', 'function ID']).mean(numeric_only=True)\n",
    "    df_means = df_means.drop(columns=['instance ID', 'repetition'])\n",
    "    df_means = df_means.reset_index()\n",
    "    return df_means\n",
    "\n",
    "def aggregateByStd(df):\n",
    "    df_std = df.groupby(by=['Representation', 'ndim', 'function ID']).std()\n",
    "    df_std = df_std.drop(columns=['instance ID', 'repetition'])\n",
    "    df_std = df_std.reset_index()\n",
    "    return df_std\n",
    "\n",
    "def aggregateByMax(df):\n",
    "    df_means = df.groupby(by=['Representation', 'ndim', 'function ID']).max(axis=1)\n",
    "    df_means = df_means.drop(columns=['instance ID', 'repetition'])\n",
    "    df_means = df_means.reset_index()\n",
    "    return df_means\n",
    "\n",
    "def aggregateByMedian(df):\n",
    "    df_means = df.groupby(by=['Representation', 'ndim', 'function ID']).median(numeric_only=True)\n",
    "    df_means = df_means.drop(columns=['instance ID', 'repetition'])\n",
    "    df_means = df_means.reset_index()\n",
    "    return df_means\n",
    "\n",
    "def aggregateBy(df, aggregation):\n",
    "    if aggregation == 'mean':\n",
    "        return aggregateByMean(df)\n",
    "    elif aggregation == 'std':\n",
    "        return aggregateByStd(df)\n",
    "    elif aggregation == 'max':\n",
    "        return aggregateByMax(df)\n",
    "    elif aggregation == 'median':\n",
    "        return aggregateByMedian(df)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid choice for 'aggregation': {aggregation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.449484Z",
     "start_time": "2018-05-30T11:41:13.429559Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Then we can aggregate\n",
    "# df_diff = aggregateByMax(absolutetodifferences(df))\n",
    "# df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we aggregate before calculating the differences, we can end up disrupting the monotonically decreasing nature of our data. This would result in a negative difference score!\n",
    "\n",
    "Instead, by first calculating the differences, we can then aggregate over the actually existing differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:13.469583Z",
     "start_time": "2018-05-30T11:41:13.450600Z"
    }
   },
   "outputs": [],
   "source": [
    "section_labels = ['\\inf - 10e{}'.format(powers[0])]\n",
    "section_labels.extend(['10e{} - 10e{}'.format(a, b) for a, b in zip(powers[:-1], powers[1:])])\n",
    "\n",
    "def plotOnAxis(df, columns, ax, *, title=None, legend=True):\n",
    "    for idx, row in df.iterrows():\n",
    "        ax.plot(row[columns].values, '-', label=row['Representation'])\n",
    "\n",
    "    ax.set_ylabel(\"\\'steepness\\'\")\n",
    "    ax.set_xlabel('convergence sections')\n",
    "    ax.set_xticks(np.arange(len(target_values)))\n",
    "    ax.set_xticklabels(section_labels)\n",
    "    ax.xaxis.set_tick_params(rotation=90)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if legend:\n",
    "        ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:14.506230Z",
     "start_time": "2018-05-30T11:41:13.470997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's plot the head (=first 5 rows) of the currently loaded data as an example\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plotOnAxis(df_diff.head(), columns, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:41:14.570309Z",
     "start_time": "2018-05-30T11:41:14.507748Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracting only the configurations that are best between a pair of targets rather than all 4,608...\n",
    "def selectSmallestPerColumn(df, columns, nsmallest=1):\n",
    "    indices = set()\n",
    "    for col in columns:\n",
    "        if df[col].max() > 0:\n",
    "            new_indices = set(df[col].nsmallest(nsmallest).axes[0])\n",
    "            indices = indices.union(new_indices)\n",
    "    return df.iloc[sorted(indices)]\n",
    "\n",
    "selectSmallestPerColumn(df_diff, columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:18.464966Z",
     "start_time": "2018-05-30T11:41:14.571486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we plot all differences for each configuration that is best between at least one pair of targets\n",
    "subset = selectSmallestPerColumn(df_diff, columns)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plotOnAxis(subset, columns, ax, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get some really large values here, which are actually not what we want to see: higher values mean bad performance.\n",
    "\n",
    "Instead, at least to visualize, it's more interesting to look at the 1/$\\delta$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:18.468872Z",
     "start_time": "2018-05-30T11:42:18.466118Z"
    }
   },
   "outputs": [],
   "source": [
    "def makecleaninverses(df, columns):\n",
    "    return_df = df.copy()\n",
    "    for col in columns:\n",
    "        return_df[col] = 1/df[col]\n",
    "    return_df = return_df.replace(np.inf, np.NaN)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:21.992042Z",
     "start_time": "2018-05-30T11:42:18.470255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we plot all differences for each configuration that is best between at least one pair of targets\n",
    "subset = makecleaninverses(selectSmallestPerColumn(df_diff, columns), columns)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plotOnAxis(subset, columns, ax, legend=False)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:21.996655Z",
     "start_time": "2018-05-30T11:42:21.993705Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#SOME DEBUGGING INFO\n",
    "# idx = df_diff[columns[14]].nsmallest(1).axes[0]\n",
    "# print(idx)\n",
    "# rep = df_diff.iloc[idx]['Representation'].values[0]\n",
    "# print(rep)\n",
    "\n",
    "# subset = df[df['Representation'] == rep]\n",
    "\n",
    "# print(idx)\n",
    "# print(subset.as_matrix(columns).astype(int))\n",
    "# print(df_diff.iloc[idx].as_matrix(columns))\n",
    "\n",
    "#SOME DEBUGGING INFO\n",
    "# print(absolutetodifferences(aggregateByMean(subset)).as_matrix(columns).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:22.836826Z",
     "start_time": "2018-05-30T11:42:21.997939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just some caching\n",
    "full_data = {(ndim, fid): get_data(ndim=ndim, fid=fid) for ndim, fid in product(ndims, fids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:33.551488Z",
     "start_time": "2018-05-30T11:42:22.838324Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Because it's defined as a simple-to-use function, we can now plot this data for all available datasets\n",
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(12,8), sharex=True, sharey=True)\n",
    "\n",
    "for exp, ax in zip(product(ndims, fids), axes.flatten()):\n",
    "    ndim, fid = exp\n",
    "#     df_means = aggregateByMean(absolutetodifferences(full_data[(ndim, fid)]))\n",
    "    df_means = absolutetodifferences(full_data[(ndim, fid)])\n",
    "    subset = makecleaninverses(selectSmallestPerColumn(df_means, columns), columns)\n",
    "    plotOnAxis(subset, columns, ax, title='{}D F{}'.format(ndim, fid), legend=False)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:33.629811Z",
     "start_time": "2018-05-30T11:42:33.552611Z"
    }
   },
   "outputs": [],
   "source": [
    "df_diff = absolutetodifferences(get_data(ndim=5, fid=1))\n",
    "df_diff[columns] = df_diff[columns].replace(0, np.NaN)  # we replace 0 by NaN so they're automatically excluded\n",
    "# df_diff = aggregateByMax(df_diff)\n",
    "subset = selectSmallestPerColumn(df_diff, columns)\n",
    "\n",
    "# And now the hypothetical result if we take the best sub-result per section...\n",
    "print(subset[columns].min(axis=0))\n",
    "print(subset[columns].min(axis=0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:33.914296Z",
     "start_time": "2018-05-30T11:42:33.630881Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def findlastreachedcolumn(df, columns):\n",
    "    actual_best = np.NaN\n",
    "    col_idx = 0\n",
    "    while np.isnan(actual_best):\n",
    "        col_idx += 1\n",
    "        actual_best = df[columns[-col_idx]].min()\n",
    "\n",
    "    return columns[-col_idx]\n",
    "\n",
    "\n",
    "def calcresults(data):\n",
    "    records = []\n",
    "    labels = ['ndim', 'fid', 'Target', 'Empirical best', 'Adaptive best', 'Relative improvement']\n",
    "    for ndim, fid in product(ndims, fids):\n",
    "        df = data[(ndim, fid)]\n",
    "\n",
    "#         df_means = aggregateByMean(df)\n",
    "        last_column = findlastreachedcolumn(df, columns)\n",
    "        actual_best = df[last_column].min()\n",
    "\n",
    "        df_diff = absolutetodifferences(df)\n",
    "        df_diff[columns] = df_diff[columns].replace(0, np.NaN)\n",
    "#         df_diff = aggregateByMax(df_diff)\n",
    "        subset = selectSmallestPerColumn(df_diff, columns)\n",
    "        theory_best = subset[columns].min(axis=0).sum()\n",
    "\n",
    "        rel_improvement = 1-(theory_best/actual_best)\n",
    "\n",
    "        records.append((ndim, fid, last_column, actual_best, theory_best, rel_improvement))\n",
    "\n",
    "    results = pd.DataFrame.from_records(records, columns=labels)\n",
    "    return results\n",
    "\n",
    "print(calcresults(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:35.037313Z",
     "start_time": "2018-05-30T11:42:33.915278Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = 'stepwise_ERT_data_{ndim}D-f{fid}.csv'  # Using different files\n",
    "old_full_data = full_data\n",
    "full_data = {(ndim, fid): get_data(ndim=ndim, fid=fid) for ndim, fid in product(ndims, fids)}\n",
    "\n",
    "print(calcresults(full_data))\n",
    "\n",
    "file_name = 'ERT_data_{ndim}D-f{fid}.csv'  # resetting the variable...\n",
    "full_data = old_full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative approach: Limited splits\n",
    "\n",
    "So far we've looked at finding the optimal performance when you can pick the best convergence in between each pair of targets. Practically, this is not really feasible as you would need to make sure when exactly you are switching, which is very difficult in a black-box setting.\n",
    "\n",
    "But, as we've seen that there are (significant) gains to be made, so let's scale it down. Instead of allowing arbitrary switching, what happens if we allow only a few switches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:35.066541Z",
     "start_time": "2018-05-30T11:42:35.038841Z"
    }
   },
   "outputs": [],
   "source": [
    "def determinebestsplit(df, columns, *, numsplits=1, aggregation='mean'):\n",
    "    best_split_idx = 0\n",
    "    best_value = np.inf\n",
    "    final_column_idx = columns.index(findlastreachedcolumn(df, columns))\n",
    "\n",
    "    for split in range(1,final_column_idx):\n",
    "        \n",
    "        part1 = df[df.columns[3:]]\n",
    "        part1 = part1.assign(values=(df[columns[split]]))\n",
    "\n",
    "        part2 = df[df.columns[3:]]\n",
    "        part2 = part2.assign(values=(df[columns[final_column_idx]] - df[columns[split]]))\n",
    "\n",
    "        part1_idx = part1['values'].idxmin()\n",
    "        val1 = part1.iloc[part1_idx]['values']\n",
    "        x = part1.iloc[part1_idx]\n",
    "\n",
    "        part2_idx = part2['values'].idxmin()\n",
    "        val2 = part2.iloc[part2_idx]['values']\n",
    "        x = part2.iloc[part2_idx]\n",
    "\n",
    "        if val1+val2 < best_value:\n",
    "            best_value = val1+val2\n",
    "            best_split_idx = split\n",
    "            best_idx_1, best_idx_2 = part1_idx, part2_idx\n",
    "    \n",
    "    return best_value, best_split_idx, best_idx_1, best_idx_2\n",
    "\n",
    "\n",
    "def calculatesplitbasedrecord(df, aggregation='mean'):\n",
    "    value, split_idx, part1_idx, part2_idx = determinebestsplit(df, columns, aggregation=aggregation)\n",
    "\n",
    "    last_column = findlastreachedcolumn(df, columns)\n",
    "    actual_best_idx = df[last_column].idxmin()\n",
    "    actual_best_value = df.iloc[actual_best_idx][last_column]\n",
    "    \n",
    "    return (actual_best_value, value, 1-(value/actual_best_value), \n",
    "            columns[split_idx], actual_best_idx, part1_idx, part2_idx)\n",
    "\n",
    "\n",
    "def calculatesplitbasedoverview(data, cases, *, aggregation='mean'):\n",
    "    records = []\n",
    "    for ndim, fid in cases:\n",
    "        df = data[(ndim, fid)]\n",
    "        record = calculatesplitbasedrecord(df, aggregation=aggregation)\n",
    "        records.append((ndim, fid, *record))\n",
    "\n",
    "    labels = ['ndim', 'fid', 'Static', 'Adaptive', 'relative improvement', \n",
    "              'split', 'Static index', '$C_1$ index', '$C_{\\\\Gamma}$ index']\n",
    "    results = pd.DataFrame.from_records(records, columns=labels)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:36.462541Z",
     "start_time": "2018-05-30T11:42:35.067668Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_split_overview = calculatesplitbasedoverview(product(ndims, fids))\n",
    "# print(mean_split_overview)\n",
    "split_overview = calculatesplitbasedoverview(full_data, product(ndims, fids))\n",
    "print(split_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:36.485319Z",
     "start_time": "2018-05-30T11:42:36.463542Z"
    }
   },
   "outputs": [],
   "source": [
    "def displayoverview(overview, data):\n",
    "    representations = defaultdict(list)\n",
    "    cols = ['Static index', '$C_1$ index', '$C_{\\\\Gamma}$ index']\n",
    "    for idx, row in overview.iterrows():\n",
    "        df = data[(row.loc['ndim'], row.loc['fid'])]\n",
    "        for column in cols:\n",
    "            representations[column[:-6]+' rep'].append(df.iloc[row.loc[column]]['Representation'].replace(' ', ''))\n",
    "        \n",
    "    disp_overview = overview.assign(**representations)\n",
    "    disp_overview = disp_overview.drop(columns=cols)\n",
    "    \n",
    "    return disp_overview\n",
    "    \n",
    "displayoverview(split_overview, full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows are a some plots of convergence behavior:\n",
    " * 1) the best original configuration\n",
    " * 2) the (entire) configuration that performs best **before** the split (**part1**)\n",
    " * 3) the (entire) configuration that performs best **after** the split (**part2**)\n",
    " * 4) the **compound** performance of **part1** before the split and **part2** after the split\n",
    " \n",
    "NOTE:\n",
    "The plots currently only give an indication of what we would like to see. Until the vertical line (i.e., the split location), the compound line follows the convergence of ***part1***, and follows the behavior of ***part2*** after the split. \n",
    "\n",
    "For now, the results are not what we would expect, as the red line (compound) should always result in reaching the furthest target with the lowest hitting time. The reason for this, is that these results are (for now) plotted using the mean-aggregated hitting time data, which has the problem that monotonicity is not maintained, while the **calculations** are done on the differences. This still has to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:45.270017Z",
     "start_time": "2018-05-30T11:42:36.486451Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotCompoundOnAxis(df, row, ax, *, title='', log=False):\n",
    "    for column in ['Static index', '$C_1$ index', '$C_{\\\\Gamma}$ index']:\n",
    "        orig_idx = int(row.loc[column])\n",
    "        ax.plot(df.iloc[orig_idx][columns].values, '-', label=column[:-6])\n",
    "\n",
    "    split_idx = columns.index(row.loc['split'])\n",
    "    idx1 = row.loc['$C_1$ index']\n",
    "    part1 = df.iloc[idx1][columns[:split_idx+1]].values\n",
    "\n",
    "    idx2 = row.loc[r\"$C_{\\Gamma}$ index\"]\n",
    "    part2 = df.iloc[idx2][columns[split_idx:]].values\n",
    "    part2 = (part2 - part2[0]) + df.iloc[idx1][columns[split_idx]]\n",
    "    compound = np.concatenate((part1, part2[1:]))\n",
    "    ax.plot(compound, '-', label='Adaptive')\n",
    "\n",
    "    num_valids = len(compound[~np.isnan(compound.astype(np.float))])\n",
    "    \n",
    "    ax.axvline(split_idx, linewidth=1, color='black')\n",
    "\n",
    "    ax.set_ylabel(\"AHT\")\n",
    "    ax.set_xlabel(r\"$\\phi$\")\n",
    "    ax.set_xticks(np.arange(len(target_values))[::5])\n",
    "    ax.set_xticklabels(target_values[::5])\n",
    "    ax.set_xlim([0, num_valids])\n",
    "    ax.xaxis.set_tick_params(rotation=90)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc=0)\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    \n",
    "    \n",
    "\n",
    "def plotCompounds(overview, data, cases, fig, *, log=defaultdict(lambda: False), save_name=None):    \n",
    "    \n",
    "    for idx, row in overview.iterrows():\n",
    "\n",
    "        exp, ax = cases[idx]\n",
    "        ndim, fid = exp\n",
    "        title = '{ndim}D F{fid}'.format(ndim=ndim, fid=fid)\n",
    "        df = data[(ndim, fid)]\n",
    "\n",
    "        plotCompoundOnAxis(df, row, ax, title=title, log=log[(ndim, fid)])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_name:\n",
    "        fig.savefig(save_name+'.pdf')\n",
    "        fig.savefig(save_name+'.png')\n",
    "\n",
    "log = defaultdict(lambda: True, {(5, 1): False, (5, 10): False})\n",
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(12,8))\n",
    "cases = list(zip(product(ndims, fids), axes.flatten()))\n",
    "\n",
    "plotCompounds(split_overview, full_data, cases, fig, log=log, save_name='interpolated_ERT_splits')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for 5D F1 and F10 are the clearest and most promising. Especially 5D F10 shows how `part 2` has a clear knee-point that is optimally identified and suggests a potential improvement of over 16%.\n",
    "\n",
    "On the other hand, the results for 20D F20 seem not very informative as most target values are not reached.\n",
    "\n",
    "The remaining functions are dominated by ERT scores that are near the maximum, i.e., only a few runs succeeded up to the point where the split is identified. After that, the behavior is no longer determined by the `max_budget` penalty for every failed run, but only the behavior of those runs that did succeed is taken into account in determining these results. This makes the approach a greedy one, that is fine with taking the risk that several runs will not succeed, simply because after a while, it can ignore the penalty given for that. Note that this is an inherent problem of aggregating in any way over a set of runs which did not all reach the desired target value, regardless of whether it is measured by ERT or bootstrapped aRT.\n",
    "\n",
    "An alternative explanation might be that these are configurations that require a lot of time to learn internal parameters before 'getting in the flow' that allows them to make progress in the optimization task. (B)IPOP with its adaptive population size is an example of a module that could exhibit such behavior. If that is the case, it would be interesting to examine the parameter values when the knee-point occurs. At the same time, it would have to be taken into account when implementing this in an actual adaptive configuration setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaving out (B)IPOP variants\n",
    "\n",
    "To examine the potential influence of the second possible explanation in the previous section, we now repeat the experiment with all (B)IPOP variants excluded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:45.315449Z",
     "start_time": "2018-05-30T11:42:45.271278Z"
    }
   },
   "outputs": [],
   "source": [
    "def filterbipop(df):\n",
    "    df = df.assign(bipop=df['Representation'].astype(str).str[28] != '0')\n",
    "    df = df[df['bipop'] == False]\n",
    "    df = df.drop(columns=['bipop'])\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "filtered_data = {(ndim, fid): filterbipop(full_data[(ndim, fid)]) for ndim, fid in product(ndims, fids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:46.417235Z",
     "start_time": "2018-05-30T11:42:45.316620Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_split_overview = calculatesplitbasedoverview(filtered_data, product(ndims, fids))\n",
    "displayoverview(filtered_split_overview, filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:53.155963Z",
     "start_time": "2018-05-30T11:42:46.418295Z"
    }
   },
   "outputs": [],
   "source": [
    "log = defaultdict(lambda: True, {(5, 1): False, (5, 10): False})\n",
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(12,8))\n",
    "cases = list(zip(product(ndims, fids), axes.flatten()))\n",
    "\n",
    "plotCompounds(filtered_split_overview, filtered_data, cases, fig, log=log, save_name='no-bipop_interpolated_ERT_splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the results seem the same: Only 5D F1 and F10 can really be plotted without having to resort to a log-scale. The most noticable thing is that the best 'regular' results are now worse than before, as the succesful (B)IPOP module is no longer allowed in the configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only fully successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're still dealing with the fitness 'jumps' caused by the ERT calculation, we'll now look only at those configurations which were 100% successful. This does mean we will reach fewer targets, but those results will not be distorted and are therefore more reliable.\n",
    "\n",
    "Note: (for now) this is only a one-time filter based on the smallest convergence target. Especially for the single-split variant, it may still be interesting to perform this filter for every possible 'part1' by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:57.358032Z",
     "start_time": "2018-05-30T11:42:53.157095Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = 'interpolated_ART_data_{ndim}D-f{fid}.csv'\n",
    "\n",
    "raw_data = {(ndim, fid): get_data(ndim=ndim, fid=fid) for ndim, fid in product(ndims, fids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:57.363822Z",
     "start_time": "2018-05-30T11:42:57.358985Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregateByFilteredERT(df, max_budget):\n",
    "    df = df.drop(columns=['instance ID', 'repetition'])\n",
    "\n",
    "    sums = df.fillna(max_budget).groupby(by=['Representation', 'ndim', 'function ID']).sum()\n",
    "    counts = df.groupby(by=['Representation', 'ndim', 'function ID']).count()\n",
    "    \n",
    "    # Count how many runs should be successful and discard anything below that value\n",
    "    max_successful = counts.max()[0]\n",
    "    counts[counts != max_successful] = np.NaN\n",
    "    \n",
    "    ERTs = sums/counts\n",
    "    ERTs = ERTs.replace(np.inf, np.NaN).reset_index()\n",
    "    return ERTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:58.479564Z",
     "start_time": "2018-05-30T11:42:57.364932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some caching again\n",
    "successful_only_data = {(ndim, fid): aggregateByFilteredERT(raw_data[(ndim, fid)], max_budget=ndim*10e4) for ndim, fid in product(ndims, fids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:58.736146Z",
     "start_time": "2018-05-30T11:42:58.480604Z"
    }
   },
   "outputs": [],
   "source": [
    "calcresults(successful_only_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:42:59.699762Z",
     "start_time": "2018-05-30T11:42:58.737532Z"
    }
   },
   "outputs": [],
   "source": [
    "successful_split_overview = calculatesplitbasedoverview(successful_only_data, product(ndims, fids))\n",
    "displayoverview(successful_split_overview, successful_only_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:43:07.035623Z",
     "start_time": "2018-05-30T11:42:59.700765Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(12,8))\n",
    "cases = list(zip(product(ndims, fids), axes.flatten()))\n",
    "\n",
    "plotCompounds(successful_split_overview, successful_only_data, cases, fig,\n",
    "              save_name='successful_only_interpolated_ERT_splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:43:14.003608Z",
     "start_time": "2018-05-30T11:43:07.036620Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = product(ndims, fids[:2])\n",
    "selection = successful_split_overview.iloc[[0,1,4,5]].reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(9,6))\n",
    "cases = list(zip(experiments, axes.flatten()))\n",
    "\n",
    "plotCompounds(selection, successful_only_data, cases, fig, \n",
    "              save_name='successful_only_interpolated_ERT_splits_p1')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T11:43:21.480984Z",
     "start_time": "2018-05-30T11:43:14.004892Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = product(ndims, fids[2:])\n",
    "selection = successful_split_overview.iloc[[2,3,6,7]].reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(9,6))\n",
    "cases = list(zip(experiments, axes.flatten()))\n",
    "\n",
    "plotCompounds(selection, successful_only_data, cases, fig, \n",
    "              save_name='successful_only_interpolated_ERT_splits_p2')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
